{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8050dfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import noisereduce as nr\n",
    "import librosa\n",
    "import birdnetlib\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from collections import Counter\n",
    "from tensorflow.lite.python.interpreter import Interpreter\n",
    "from pprint import pprint \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d492b5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from birdnetlib import Recording\n",
    "from birdnetlib.analyzer import Analyzer\n",
    "from birdnetlib.batch import DirectoryMultiProcessingAnalyzer\n",
    "from birdnetlib.species import SpeciesList\n",
    "from birdnetlib.watcher import DirectoryWatcher\n",
    "from datetime import datetime \n",
    "import re \n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4c095ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_directory(dir_path):\n",
    "    if os.path.exists(dir_path):\n",
    "        shutil.rmtree(dir_path)\n",
    "    os.mkdir(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3382ad17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_file(filename):\n",
    "    pattern = r\"(\\d{8})_(\\d{6})\"\n",
    "    match = re.search(pattern, filename)\n",
    "    date, time = match.groups()\n",
    "    return datetime.strptime(date + time, \"%Y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e27a0395",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_file(recording):\n",
    "    print(\"\\n\" + recording.path)\n",
    "    pprint(recording.date)\n",
    "    print(\"predicted species: \\n\")\n",
    "    species_pred = SpeciesList()\n",
    "    species_predicted = species_pred.return_list(lon=105.398278, lat=11.403694, \n",
    "                                                    date=recording.date, threshold=0.75)\n",
    "    pprint(species_predicted)\n",
    "    print(\"detected species: \\n\")\n",
    "    pprint(recording.detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "885f132d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def directory_analyzer():\n",
    "\n",
    "    analyzers = {\n",
    "        \"default\": Analyzer(),\n",
    "        \"full_species\": Analyzer(custom_species_list_path=\"species_lists/full_species_list.txt\"),\n",
    "        \"main_species\": Analyzer(custom_species_list_path=\"species_lists/main_species_list.txt\"),\n",
    "    }\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    export_dir = f\"extractions/extractions_{timestamp}\"\n",
    "    os.makedirs(export_dir, exist_ok=True)\n",
    "\n",
    "    csv_path = os.path.join(export_dir, f\"detections_{timestamp}.csv\")\n",
    "    csv_headers = [\n",
    "        \"file_name\", \"analyzer\", \"common_name\", \"scientific_name\", \"confidence\",\n",
    "        \"start_time\", \"end_time\", \"extracted_audio_path\", \"extracted_spectrogram_path\",\n",
    "        \"is_expected\", \"lat\", \"lon\", \"date\"\n",
    "    ]\n",
    "\n",
    "    with open(csv_path, mode=\"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=csv_headers)\n",
    "        writer.writeheader()\n",
    "\n",
    "        directory = \"aru\"\n",
    "        lat, lon = 11.403694, 105.398278\n",
    "\n",
    "        audio_files = [os.path.join(directory, f) for f in os.listdir(directory)\n",
    "                    if f.lower().endswith((\".wav\", \".mp3\"))]\n",
    "\n",
    "        for file_path in audio_files:\n",
    "            file_name = os.path.basename(file_path)\n",
    "            file_date = date_file(file_name)\n",
    "\n",
    "            species_pred = SpeciesList()\n",
    "            predicted_species = species_pred.return_list(\n",
    "                lon=lon, lat=lat, date=file_date, threshold=0.5\n",
    "            )\n",
    "            predicted_species_names = {s[\"common_name\"] for s in predicted_species}\n",
    "\n",
    "            for analyzer_name, analyzer in analyzers.items():\n",
    "                try:\n",
    "                    if analyzer.has_custom_species_list:\n",
    "                        rec = Recording(\n",
    "                            analyzer,\n",
    "                            file_path,\n",
    "                            date=file_date,\n",
    "                            return_all_detections=True,\n",
    "                            min_conf=0.5\n",
    "                        )\n",
    "                    else:\n",
    "                        rec = Recording(\n",
    "                            analyzer,\n",
    "                            file_path,\n",
    "                            lat=lat,\n",
    "                            lon=lon,\n",
    "                            date=file_date,\n",
    "                            return_all_detections=True,\n",
    "                            min_conf=0.5\n",
    "                        )\n",
    "\n",
    "                    rec.analyze()\n",
    "\n",
    "                    rec.extract_detections_as_audio(\n",
    "                        directory=export_dir, format=\"mp3\", min_conf=0.5, padding_secs=2\n",
    "                    )\n",
    "                    rec.extract_detections_as_spectrogram(\n",
    "                        directory=export_dir, min_conf=0.5, padding_secs=2\n",
    "                    )\n",
    "\n",
    "                    filtered_detections = [\n",
    "                        detection for detection in rec.detections\n",
    "                        if detection.get(\"confidence\", 0) >= 0.5\n",
    "                    ]\n",
    "                    \n",
    "                    def normalise_name(name):\n",
    "                        return re.sub(r\"[^a-z]\", \"\", name.lower())\n",
    "                    normalised_predicted_names = {normalise_name(n) for n in predicted_species_names}\n",
    "\n",
    "                    for detection in filtered_detections:\n",
    "                        is_expected = normalise_name(detection.get(\"common_name\", \"\")) in normalised_predicted_names\n",
    "                        writer.writerow({\n",
    "                            \"file_name\": file_name,\n",
    "                            \"analyzer\": analyzer_name,\n",
    "                            \"common_name\": detection.get(\"common_name\", \"\"),\n",
    "                            \"scientific_name\": detection.get(\"scientific_name\", \"\"),\n",
    "                            \"confidence\": round(detection.get(\"confidence\", 0), 4),\n",
    "                            \"start_time\": detection.get(\"start_time\", \"\"),\n",
    "                            \"end_time\": detection.get(\"end_time\", \"\"),\n",
    "                            \"extracted_audio_path\": detection.get(\"extracted_audio_path\", \"\"),\n",
    "                            \"extracted_spectrogram_path\": detection.get(\"extracted_spectrogram_path\", \"\"),\n",
    "                            \"is_expected\": is_expected,\n",
    "                            \"lat\": lat,\n",
    "                            \"lon\": lon,\n",
    "                            \"date\": file_date.strftime(\"%Y-%m-%d\"),\n",
    "                        })\n",
    "                except Exception as e:\n",
    "                    print(f\"extraction failed for {file_path} with analyzer {analyzer_name}: {e}\")\n",
    "\n",
    "    print(f\"\\ndetections saved to: {csv_path}\")\n",
    "    print(f\"mp3s and spectrograms saved in: {export_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "82cb4b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels loaded.\n",
      "load model True\n",
      "Model loaded.\n",
      "Labels loaded.\n",
      "load_species_list_model\n",
      "Meta model loaded.\n",
      "Labels loaded.\n",
      "load model True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anku2024/Documents/clink lab/boeung-sne/birdc/lib/python3.9/site-packages/tensorflow/lite/python/interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n",
      "Labels loaded.\n",
      "load_species_list_model\n",
      "Meta model loaded.\n",
      "Anastomus oscitans_Asian Openbill\n",
      "\n",
      "Nycticorax nycticorax_Black-crowned Night-Heron\n",
      "\n",
      "Pelecanus philippensis_Spot-billed Pelican\n",
      "\n",
      "Mycteria leucocephala_Painted Stork\n",
      "\n",
      "Threskiornis melanocephalus_Black-headed Ibis\n",
      "\n",
      "Plegadis falcinellus_Glossy Ibis\n",
      "\n",
      "Ardea alba_Great White Egret\n",
      "\n",
      "Ardea intermedia_Medium Egret\n",
      "\n",
      "Egretta garzetta_Little Egret\n",
      "\n",
      "Ardea coromanda_Eastern Cattle-Egret\n",
      "\n",
      "Leptoptilos javanicus_Lesser Adjutant\n",
      "\n",
      "Leptoptilos dubius_Greater Adjutant\n",
      "\n",
      "Pseudibis davisoni_White-shouldered Ibis\n",
      "\n",
      "Microcarbo niger_Little Cormorant\n",
      "\n",
      "Phalacrocorax fuscicollis_Indian Cormorant\n",
      "\n",
      "Phalacrocorax carbo_Great Cormorant\n",
      "\n",
      "Anhinga melanogaster_Oriental Darter\n",
      "\n",
      "Ardea cinerea_Grey Heron\n",
      "\n",
      "Ardea purpurea_Purple Heron\n",
      "\n",
      "Ardeola bacchus_Chinese Pond Heron\n",
      "\n",
      "Ardeola speciosa_Javan Pond Heron\n",
      "\n",
      "Botaurus sinensis_Yellow Bittern\n",
      "\n",
      "Botaurus cinnamomeus_Cinnamon Bittern\n",
      "\n",
      "Botaurus flavicollis_Black Bittern\n",
      "\n",
      "Butorides striata_Striated Heron\n",
      "\n",
      "Geopelia striata_Zebra Dove\n",
      "\n",
      "Spilopelia chinensis_Spotted Dove\n",
      "\n",
      "Streptopelia tranquebarica_Red Collared Dove\n",
      "\n",
      "Eudynamys scolopaceus_Asian Koel\n",
      "\n",
      "Cacomantis merulinus_Plaintive Cuckoo\n",
      "\n",
      "Centropus sinensis_Greater Coucal\n",
      "\n",
      "Centropus bengalensis_Lesser Coucal\n",
      "\n",
      "Cypsiurus balasiensis_Asian Palm Swift\n",
      "\n",
      "Amaurornis phoenicurus_White-breasted Waterhen\n",
      "\n",
      "Himantopus himantopus_Black-winged Stilt\n",
      "\n",
      "Vanellus indicus_ Red-wattled Lapwing\n",
      "\n",
      "Glareola maldivarum_Oriental Pratincole\n",
      "\n",
      "Chlidonias hybrida_Whiskered Tern\n",
      "\n",
      "Tyto javanica_Eastern Barn Owl\n",
      "\n",
      "Merops orientalis_Asian Green Bee-eater\n",
      "\n",
      "Merops philippinus_Blue-tailed Bee-eater\n",
      "\n",
      "Alcedo atthis_Common Kingfisher\n",
      "\n",
      "Halcyon smyrnensis_White-throated Kingfisher\n",
      "\n",
      "Halcyon pileata_ Black-capped Kingfisher\n",
      "\n",
      "Ceryle rudis_Pied Kingfisher\n",
      "\n",
      "Psilopogon haemacephalus_Coppersmith Barbet\n",
      "\n",
      "Dendrocopos analis_Freckle-breasted Woodpecker\n",
      "\n",
      "Oriolus chinensis_Black-naped Oriole\n",
      "\n",
      "Aegithina tiphia_Common Iora\n",
      "\n",
      "Rhipidura javanica_Malaysian Pied-fantail\n",
      "\n",
      "Dicrurus macrocercus_Black Drongo\n",
      "\n",
      "Lanius cristatus_Brown Shrike\n",
      "\n",
      "Crypsirina temia_Racket-tailed Treepie\n",
      "\n",
      "Corvus macrorhynchos_Large-billed Crow\n",
      "\n",
      "Orthotomus sutorius_Common Tailorbird\n",
      "\n",
      "Orthotomus atrogularis_Dark-necked Tailorbird\n",
      "\n",
      "Prinia flaviventris_Yellow-bellied Privia\n",
      "\n",
      "Prinia inornata_Plain Prinia\n",
      "\n",
      "Acrocephalus orientalis_Oriental Reed Warbler\n",
      "\n",
      "Helopsaltes certhiola_Pallasâ€™s Grasshopper Warbler \n",
      "\n",
      "Hirundo rustica_Barn Swallow\n",
      "\n",
      "Pycnonotus conradi_Streak-eared Bulbul\n",
      "\n",
      "Pycnonotus goiavier_Yellow-vented Bulbul\n",
      "\n",
      "Phylloscopus inornatus_Yellow-browed Warbler \n",
      "\n",
      "Timalia pileata_Chestnut-capped Babbler\n",
      "\n",
      "Mixornis gularis_Pin-striped Tit-babbler\n",
      "\n",
      "Gracupica nigricollis_Black-collared Starling\n",
      "\n",
      "Sturnia malabarica_Chestnut-tailed Starling\n",
      "\n",
      "Acridotheres tristis_Common Myna\n",
      "\n",
      "Acridotheres grandis_Great Myna\n",
      "\n",
      "Copsychus saularis_Oriental Magpie Robin\n",
      "\n",
      "Ficedula albicilla_Taiga Flycatcher\n",
      "\n",
      "Saxicola caprata_Pied Bushchat\n",
      "\n",
      "Dicaeum cruentatum_Scarlet-backed Flowerpecker\n",
      "\n",
      "Anthreptes malacensis_Brown-throated Sunbird\n",
      "\n",
      "Cinnyris asiaticus_Purple Sunbird\n",
      "\n",
      "Cinnyris ornatus_Ornate Sunbird\n",
      "\n",
      "Ploceus philippinus_Baya Weaver\n",
      "\n",
      "Lonchura punctulata_Scaly-breasted Munia\n",
      "\n",
      "Passer domesticus_House Sparrow\n",
      "\n",
      "Passer montanus_Eurasian Tree Sparrow\n",
      "81 species loaded.\n",
      "Labels loaded.\n",
      "load model True\n",
      "Model loaded.\n",
      "Labels loaded.\n",
      "load_species_list_model\n",
      "Meta model loaded.\n",
      "Anastomus oscitans_Asian Openbill\n",
      "\n",
      "Nycticorax nycticorax_Black-crowned Night-Heron\n",
      "\n",
      "Pelecanus philippensis_Spot-billed Pelican\n",
      "\n",
      "Mycteria leucocephala_Painted Stork\n",
      "\n",
      "Threskiornis melanocephalus_Black-headed Ibis\n",
      "\n",
      "Plegadis falcinellus_Glossy Ibis\n",
      "\n",
      "Ardea coromanda_Eastern Cattle-Egret\n",
      "7 species loaded.\n",
      "Labels loaded.\n",
      "load_species_list_model\n",
      "Meta model loaded.\n",
      "5\n",
      "63 species loaded.\n",
      "read_audio_data\n",
      "read_audio_data: complete, read  200 chunks.\n",
      "analyze_recording 3_S7901_20250204_070000(UTC+7).wav\n",
      "recording has lon/lat\n",
      "set_predicted_species_list_from_position\n",
      "return_predicted_species_list\n",
      "5\n",
      "511 species loaded.\n",
      "read_audio_data\n",
      "read_audio_data: complete, read  200 chunks.\n",
      "analyze_recording 3_S7901_20250204_070000(UTC+7).wav\n",
      "read_audio_data\n",
      "read_audio_data: complete, read  200 chunks.\n",
      "analyze_recording 3_S7901_20250204_070000(UTC+7).wav\n",
      "\n",
      "detections saved to: extractions/extractions_2025-11-05_18-02-22/detections_2025-11-05_18-02-22.csv\n",
      "mp3s and spectrograms saved in: extractions/extractions_2025-11-05_18-02-22\n"
     ]
    }
   ],
   "source": [
    "directory_analyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "83a45f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def directory_watcher():\\n    \\n    analyzer_default = Analyzer()\\n    \\n    analyzer_full_species = Analyzer(\\n        custom_species_list_path=\"species_lists/full_species_list.txt\")\\n    \\n    analyzer_main_species = Analyzer(\\n        custom_species_list_path=\"species_lists/main_species_list.txt\")\\n    \\n    def preanalyze(recording): \\n        recording.date = date_file(recording.filename)\\n    \\n    def on_analyze_complete(recording):\\n        print(f\"\\n{recording.path} analysed by {recording.analyzer.name}\")\\n        \\n    def on_analyze_file_complete(recording_list):\\n        for recording in recording_list:\\n            print(f\"\\n{recording.filename} ( {recording.analyzer.name} )\")\\n            \\n            print(\"predicted species: \\n\")\\n            species_pred = SpeciesList()\\n            species_predicted = species_pred.return_list(lon=105.398278, lat=11.403694, \\n                                                    date=recording.date, threshold=0.75)\\n            pprint(species_predicted)\\n            print(\"detected species: \\n\")\\n            pprint(recording.detections)\\n            \\n            export_dir = f\"extractions/{recording.analyzer.name}_extractions\"\\n            clear_directory(export_dir)\\n            recording.extract_detections_as_audio(directory=export_dir,\\n                                            format=\"mp3\", min_conf=0.5, padding_secs=2)\\n            recording.extract_detections_as_spectrogram(directory=export_dir,\\n                                            min_conf=0.5, padding_secs=2)\\n            \\n    def on_error(recording, error):\\n        print(f\"error while analysing {recording.path}: {error}\")\\n        \\n    watcher = DirectoryWatcher(\\n        directory=\"aru\",\\n        analyzers=[analyzer_default, analyzer_main_species, analyzer_full_species],\\n        lon=105.398278,\\n        lat=11.403694,\\n        min_conf=0.5\\n    )\\n    \\n    watcher.recording_preanalyze = preanalyze\\n    watcher.on_analyze_complete = on_analyze_complete\\n    watcher.on_analyze_file_complete = on_analyze_file_complete\\n    watcher.on_error = on_error\\n    \\n    watcher.watch()'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def directory_watcher():\n",
    "    \n",
    "    analyzer_default = Analyzer()\n",
    "    \n",
    "    analyzer_full_species = Analyzer(\n",
    "        custom_species_list_path=\"species_lists/full_species_list.txt\")\n",
    "    \n",
    "    analyzer_main_species = Analyzer(\n",
    "        custom_species_list_path=\"species_lists/main_species_list.txt\")\n",
    "    \n",
    "    def preanalyze(recording): \n",
    "        recording.date = date_file(recording.filename)\n",
    "    \n",
    "    def on_analyze_complete(recording):\n",
    "        print(f\"\\n{recording.path} analysed by {recording.analyzer.name}\")\n",
    "        \n",
    "    def on_analyze_file_complete(recording_list):\n",
    "        for recording in recording_list:\n",
    "            print(f\"\\n{recording.filename} ( {recording.analyzer.name} )\")\n",
    "            \n",
    "            print(\"predicted species: \\n\")\n",
    "            species_pred = SpeciesList()\n",
    "            species_predicted = species_pred.return_list(lon=105.398278, lat=11.403694, \n",
    "                                                    date=recording.date, threshold=0.75)\n",
    "            pprint(species_predicted)\n",
    "            print(\"detected species: \\n\")\n",
    "            pprint(recording.detections)\n",
    "            \n",
    "            export_dir = f\"extractions/{recording.analyzer.name}_extractions\"\n",
    "            clear_directory(export_dir)\n",
    "            recording.extract_detections_as_audio(directory=export_dir,\n",
    "                                            format=\"mp3\", min_conf=0.5, padding_secs=2)\n",
    "            recording.extract_detections_as_spectrogram(directory=export_dir,\n",
    "                                            min_conf=0.5, padding_secs=2)\n",
    "            \n",
    "    def on_error(recording, error):\n",
    "        print(f\"error while analysing {recording.path}: {error}\")\n",
    "        \n",
    "    watcher = DirectoryWatcher(\n",
    "        directory=\"aru\",\n",
    "        analyzers=[analyzer_default, analyzer_main_species, analyzer_full_species],\n",
    "        lon=105.398278,\n",
    "        lat=11.403694,\n",
    "        min_conf=0.5\n",
    "    )\n",
    "    \n",
    "    watcher.recording_preanalyze = preanalyze\n",
    "    watcher.on_analyze_complete = on_analyze_complete\n",
    "    watcher.on_analyze_file_complete = on_analyze_file_complete\n",
    "    watcher.on_error = on_error\n",
    "    \n",
    "    watcher.watch()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6d50a28f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'filepath = \"3_S7901_20250204_070000(UTC+7).wav\"\\nfiledate = date_file(filepath)\\n\\nanalyzer = Analyzer()\\nrecording = Recording(analyzer, filepath, \\n                    lat=11.403694, lon=105.398278, date=filedate, \\n                    return_all_detections=True, min_conf=0.5)\\n\\nrecording.analyze()\\n\\nexport_dir = \"extractions/lat_lon_extractions\"\\nclear_directory(export_dir)\\n\\nrecording.extract_detections_as_audio(directory=export_dir, format=\"mp3\", min_conf=0.5, padding_secs=2)\\nrecording.extract_detections_as_spectrogram(directory=export_dir, min_conf=0.5, padding_secs=2)\\n\\ncomplete_file(recording)'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"filepath = \"3_S7901_20250204_070000(UTC+7).wav\"\n",
    "filedate = date_file(filepath)\n",
    "\n",
    "analyzer = Analyzer()\n",
    "recording = Recording(analyzer, filepath, \n",
    "                    lat=11.403694, lon=105.398278, date=filedate, \n",
    "                    return_all_detections=True, min_conf=0.5)\n",
    "\n",
    "recording.analyze()\n",
    "\n",
    "export_dir = \"extractions/lat_lon_extractions\"\n",
    "clear_directory(export_dir)\n",
    "\n",
    "recording.extract_detections_as_audio(directory=export_dir, format=\"mp3\", min_conf=0.5, padding_secs=2)\n",
    "recording.extract_detections_as_spectrogram(directory=export_dir, min_conf=0.5, padding_secs=2)\n",
    "\n",
    "complete_file(recording)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aa7523d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'custom_list_path = \"species_lists/species_list.txt\"\\n\\nanalyzer = Analyzer(custom_species_list_path=custom_list_path)\\nrecording = Recording(analyzer, filepath, \\n                    date=filedate, \\n                    return_all_detections=True, min_conf=0.5)\\n\\nrecording.analyze()\\n\\nexport_dir = \"extractions/species_list_extractions\"\\nclear_directory(export_dir)\\n\\nrecording.extract_detections_as_audio(directory=export_dir, format=\"mp3\", min_conf=0.5, padding_secs=2)\\nrecording.extract_detections_as_spectrogram(directory=export_dir, min_conf=0.5, padding_secs=2)\\n\\ncomplete_file(recording)'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"custom_list_path = \"species_lists/species_list.txt\"\n",
    "\n",
    "analyzer = Analyzer(custom_species_list_path=custom_list_path)\n",
    "recording = Recording(analyzer, filepath, \n",
    "                    date=filedate, \n",
    "                    return_all_detections=True, min_conf=0.5)\n",
    "\n",
    "recording.analyze()\n",
    "\n",
    "export_dir = \"extractions/species_list_extractions\"\n",
    "clear_directory(export_dir)\n",
    "\n",
    "recording.extract_detections_as_audio(directory=export_dir, format=\"mp3\", min_conf=0.5, padding_secs=2)\n",
    "recording.extract_detections_as_spectrogram(directory=export_dir, min_conf=0.5, padding_secs=2)\n",
    "\n",
    "complete_file(recording)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2a3fc19d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'custom_list_path = \"species_lists/species_list_main.txt\"\\n\\nanalyzer = Analyzer(custom_species_list_path=custom_list_path)\\nrecording = Recording(analyzer, filepath, \\n                    date=filedate, \\n                    return_all_detections=True, min_conf=0.5)\\n\\nrecording.analyze()\\n\\nexport_dir = \"extractions/species_list_main_extractions\"\\nclear_directory(export_dir)\\n\\nrecording.extract_detections_as_audio(directory=export_dir, format=\"mp3\", min_conf=0.5, padding_secs=2)\\nrecording.extract_detections_as_spectrogram(directory=export_dir, min_conf=0.5, padding_secs=2)\\n\\ncomplete_file(recording)'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"custom_list_path = \"species_lists/species_list_main.txt\"\n",
    "\n",
    "analyzer = Analyzer(custom_species_list_path=custom_list_path)\n",
    "recording = Recording(analyzer, filepath, \n",
    "                    date=filedate, \n",
    "                    return_all_detections=True, min_conf=0.5)\n",
    "\n",
    "recording.analyze()\n",
    "\n",
    "export_dir = \"extractions/species_list_main_extractions\"\n",
    "clear_directory(export_dir)\n",
    "\n",
    "recording.extract_detections_as_audio(directory=export_dir, format=\"mp3\", min_conf=0.5, padding_secs=2)\n",
    "recording.extract_detections_as_spectrogram(directory=export_dir, min_conf=0.5, padding_secs=2)\n",
    "\n",
    "complete_file(recording)\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "birdc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
