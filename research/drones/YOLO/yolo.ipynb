{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80bf3a4f",
   "metadata": {},
   "source": [
    "# Drone Images\n",
    "\n",
    "- **Training:** Zones 1, 4, and 7 drone captures feeding YOLOv8.\n",
    "- **Cross-validation:** Zones 2 and 6 to stress-test generalization.\n",
    "- **Future validation:** December drone flights once the imagery is labeled.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e42d68",
   "metadata": {},
   "source": [
    "## Initial labeling\n",
    "I trained a proto model with some images from the ARU zones to help me soley with labeling the train zones where I will import the results and adjust on cvat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0748983a",
   "metadata": {},
   "source": [
    "#### The cell below will take train images, tile thenm, run inference on them using a proto model, and output the results in a format that can be imported to CVAT for labeling adjustments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6cf1b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Processing Zone 1...\n",
      "\n",
      "üñºÔ∏è Running inference on Zone 1/DJI_20250203172934_0179_V.JPG\n",
      "Performing prediction on 12 slices.\n",
      "‚úÖ Saved to:\n",
      "CVAT/images/train/DJI_20250203172934_0179_V.JPG\n",
      "CVAT/labels/train/DJI_20250203172934_0179_V.txt\n",
      "üñºÔ∏è Running inference on Zone 1/DJI_20250203174500_0618_V.JPG\n",
      "Performing prediction on 12 slices.\n",
      "‚úÖ Saved to:\n",
      "CVAT/images/train/DJI_20250203174500_0618_V.JPG\n",
      "CVAT/labels/train/DJI_20250203174500_0618_V.txt\n",
      "üñºÔ∏è Running inference on Zone 1/DJI_20250203174710_0680_V.JPG\n",
      "Performing prediction on 12 slices.\n",
      "‚úÖ Saved to:\n",
      "CVAT/images/train/DJI_20250203174710_0680_V.JPG\n",
      "CVAT/labels/train/DJI_20250203174710_0680_V.txt\n",
      "üñºÔ∏è Running inference on Zone 1/DJI_20250203172651_0102_V.JPG\n",
      "Performing prediction on 12 slices.\n",
      "‚úÖ Saved to:\n",
      "CVAT/images/train/DJI_20250203172651_0102_V.JPG\n",
      "CVAT/labels/train/DJI_20250203172651_0102_V.txt\n",
      "üñºÔ∏è Running inference on Zone 1/DJI_20250203173233_0264_V.JPG\n",
      "Performing prediction on 12 slices.\n",
      "‚úÖ Saved to:\n",
      "CVAT/images/train/DJI_20250203173233_0264_V.JPG\n",
      "CVAT/labels/train/DJI_20250203173233_0264_V.txt\n",
      "\n",
      " Processing Zone 4...\n",
      "\n",
      "üñºÔ∏è Running inference on Zone 4/DJI_20250205165502_0449_V.JPG\n",
      "Performing prediction on 12 slices.\n",
      "‚úÖ Saved to:\n",
      "CVAT/images/train/DJI_20250205165502_0449_V.JPG\n",
      "CVAT/labels/train/DJI_20250205165502_0449_V.txt\n",
      "üñºÔ∏è Running inference on Zone 4/DJI_20250205170221_0657_V.JPG\n",
      "Performing prediction on 12 slices.\n",
      "‚úÖ Saved to:\n",
      "CVAT/images/train/DJI_20250205170221_0657_V.JPG\n",
      "CVAT/labels/train/DJI_20250205170221_0657_V.txt\n",
      "\n",
      " Processing Zone 7...\n",
      "\n",
      "üñºÔ∏è Running inference on Zone 7/DJI_20250204070734_0054_V.JPG\n",
      "Performing prediction on 12 slices.\n",
      "‚úÖ Saved to:\n",
      "CVAT/images/train/DJI_20250204070734_0054_V.JPG\n",
      "CVAT/labels/train/DJI_20250204070734_0054_V.txt\n",
      "üñºÔ∏è Running inference on Zone 7/DJI_20250204070746_0060_V.JPG\n",
      "Performing prediction on 12 slices.\n",
      "‚úÖ Saved to:\n",
      "CVAT/images/train/DJI_20250204070746_0060_V.JPG\n",
      "CVAT/labels/train/DJI_20250204070746_0060_V.txt\n",
      "üñºÔ∏è Running inference on Zone 7/DJI_20250204071254_0206_V.JPG\n",
      "Performing prediction on 12 slices.\n",
      "‚úÖ Saved to:\n",
      "CVAT/images/train/DJI_20250204071254_0206_V.JPG\n",
      "CVAT/labels/train/DJI_20250204071254_0206_V.txt\n",
      "\n",
      "üéâ DONE! All annotations exported for CVAT.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from sahi import AutoDetectionModel\n",
    "from sahi.predict import get_sliced_prediction\n",
    "import shutil\n",
    "\n",
    "\n",
    "\n",
    "model_path = \"model/best.pt\"  # your YOLO model\n",
    "zone_folders = [\"Zone 1\", \"Zone 4\", \"Zone 7\"]\n",
    "output_root = \"CVAT\"\n",
    "tile_size = 1280  \n",
    "tile_overlap = 0.15  \n",
    "\n",
    "\n",
    "cvat_images = os.path.join(output_root, \"images\", \"train\")\n",
    "cvat_labels = os.path.join(output_root, \"labels\", \"train\")\n",
    "os.makedirs(cvat_images, exist_ok=True)\n",
    "os.makedirs(cvat_labels, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "detection_model = AutoDetectionModel.from_pretrained(\n",
    "    model_type=\"yolov8\",\n",
    "    model_path=model_path,\n",
    "    confidence_threshold=0.1,\n",
    "    device=\"cpu\"  # Use \"cpu\" for Mac M2\n",
    ")\n",
    "\n",
    "\n",
    "# HELPER ‚Üí WRITE YOLO TXT\n",
    "\n",
    "def save_yolo_txt(output_path, detections, img_w, img_h):\n",
    "    \"\"\"\n",
    "    SAHI returns boxes in absolute pixel coords (x1,y1,x2,y2).\n",
    "    Convert to YOLO normalized format: cls cx cy w h\n",
    "    \"\"\"\n",
    "    lines = []\n",
    "    for det in detections:\n",
    "        cls = int(det.category.id)  # already YOLO classes\n",
    "\n",
    "        x1, y1, x2, y2 = det.bbox.to_xyxy()\n",
    "        w = x2 - x1\n",
    "        h = y2 - y1\n",
    "        cx = x1 + w/2\n",
    "        cy = y1 + h/2\n",
    "\n",
    "        # normalize\n",
    "        cx /= img_w\n",
    "        cy /= img_h\n",
    "        w /= img_w\n",
    "        h /= img_h\n",
    "\n",
    "        lines.append(f\"{cls} {cx:.6f} {cy:.6f} {w:.6f} {h:.6f}\")\n",
    "\n",
    "    with open(output_path, \"w\") as f:\n",
    "        f.write(\"\\n\".join(lines))\n",
    "\n",
    "\n",
    "\n",
    "# MAIN PROCESSING LOOP\n",
    "\n",
    "for zone in zone_folders:\n",
    "    print(f\"\\n Processing {zone}...\\n\")\n",
    "\n",
    "    for filename in os.listdir(zone):\n",
    "        if not filename.lower().endswith((\"jpg\", \"jpeg\", \"png\")):\n",
    "            continue\n",
    "\n",
    "        image_path = os.path.join(zone, filename)\n",
    "        print(f\"üñºÔ∏è Running inference on {image_path}\")\n",
    "\n",
    "        # load image for size\n",
    "        img = Image.open(image_path)\n",
    "        img_w, img_h = img.size\n",
    "\n",
    "        # run SAHI sliced prediction\n",
    "        result = get_sliced_prediction(\n",
    "            image_path,\n",
    "            detection_model,\n",
    "            slice_height=tile_size,\n",
    "            slice_width=tile_size,\n",
    "            overlap_height_ratio=tile_overlap,\n",
    "            overlap_width_ratio=tile_overlap\n",
    "        )\n",
    "\n",
    "\n",
    "        out_img_path = os.path.join(cvat_images, filename)\n",
    "        out_txt_path = os.path.join(cvat_labels, filename.rsplit(\".\",1)[0] + \".txt\")\n",
    "\n",
    "        # copy original image\n",
    "        shutil.copy(image_path, out_img_path)\n",
    "\n",
    "        # save YOLO txt\n",
    "        save_yolo_txt(out_txt_path, result.object_prediction_list, img_w, img_h)\n",
    "\n",
    "        print(f\"‚úÖ Saved to:\\n{out_img_path}\\n{out_txt_path}\")\n",
    "\n",
    "print(\"\\nüéâ DONE! All annotations exported for CVAT.\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398799a7",
   "metadata": {},
   "source": [
    "### Spend like 3 hours correcting the labels and imported the correct labels... \n",
    "\n",
    "Now we can start the training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "920665c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from math import ceil\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "# ==========================\n",
    "# CONFIGURATION\n",
    "# ==========================\n",
    "INPUT_IMAGES_DIR = Path(\"CVAT/images/train\")\n",
    "INPUT_LABELS_DIR = Path(\"CVAT/labels/train\")\n",
    "\n",
    "OUTPUT_IMAGES_DIR = Path(\"TILED_YOLO/images/train\")\n",
    "OUTPUT_LABELS_DIR = Path(\"TILED_YOLO/labels/train\")\n",
    "OUTPUT_IMAGES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUT_LABELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TILE_SIZE = 1280          \n",
    "OVERLAP = 0.05             \n",
    "MIN_BOX_AREA_RATIO = 0.001 \n",
    "\n",
    "# SETTINGS FOR BETTER TRAINING\n",
    "KEEP_EMPTY_RATIO = 0.10 \n",
    "PAD_TO_SQUARE = True      # If True, edge tiles are padded to 1280x1280 with gray\n",
    "\n",
    "# ==========================\n",
    "# HELPERS\n",
    "# ==========================\n",
    "\n",
    "def yolo_to_xyxy(line, img_w, img_h):\n",
    "    parts = line.strip().split()\n",
    "    if len(parts) != 5: return None\n",
    "    cls = int(parts[0])\n",
    "    cx, cy, bw, bh = map(float, parts[1:])\n",
    "    x1 = (cx - bw / 2) * img_w\n",
    "    y1 = (cy - bh / 2) * img_h\n",
    "    x2 = (cx + bw / 2) * img_w\n",
    "    y2 = (cy + bh / 2) * img_h\n",
    "    return cls, x1, y1, x2, y2\n",
    "\n",
    "def xyxy_to_yolo(cls, x1, y1, x2, y2, tile_w, tile_h):\n",
    "    bw = x2 - x1\n",
    "    bh = y2 - y1\n",
    "    cx = x1 + bw / 2\n",
    "    cy = y1 + bh / 2\n",
    "    return f\"{cls} {cx/tile_w:.6f} {cy/tile_h:.6f} {bw/tile_w:.6f} {bh/tile_h:.6f}\"\n",
    "\n",
    "def compute_tile_starts(img_dim, tile_size, overlap):\n",
    "\n",
    "    if img_dim <= tile_size: return [0]\n",
    "    stride = int(tile_size * (1 - overlap))\n",
    "    stride = max(1, stride)\n",
    "    num_tiles = ceil((img_dim - tile_size) / stride) + 1\n",
    "    starts = []\n",
    "    for i in range(num_tiles):\n",
    "        start = i * stride\n",
    "        # Force last tile to end exactly at image edge (standard sliding window)\n",
    "        if start + tile_size > img_dim:\n",
    "            start = img_dim - tile_size\n",
    "        if not starts or start != starts[-1]:\n",
    "            starts.append(start)\n",
    "    return starts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "361a08a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting Tiling Process...\n",
      "   -> Size: 1280x1280\n",
      "   -> Keeping 10.0% of empty background tiles\n",
      "\n",
      "üéâ DONE!\n",
      "   -> Generated 117 tiles\n",
      "   -> Containing 3323 annotated birds\n",
      "   -> Saved to TILED_YOLO/images/train\n"
     ]
    }
   ],
   "source": [
    "total_tiles = 0\n",
    "total_birds = 0\n",
    "\n",
    "print(f\"üöÄ Starting Tiling Process...\")\n",
    "print(f\"   -> Size: {TILE_SIZE}x{TILE_SIZE}\")\n",
    "print(f\"   -> Keeping {KEEP_EMPTY_RATIO*100}% of empty background tiles\")\n",
    "\n",
    "for img_path in INPUT_IMAGES_DIR.iterdir():\n",
    "    if not img_path.suffix.lower() in [\".jpg\", \".jpeg\", \".png\", \".tif\"]:\n",
    "        continue\n",
    "\n",
    "    base = img_path.stem\n",
    "    label_path = INPUT_LABELS_DIR / f\"{base}.txt\"\n",
    "    \n",
    "    # Load Image\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    img_w, img_h = img.size\n",
    "    \n",
    "    # Load Labels (if exist)\n",
    "    boxes = []\n",
    "    if label_path.exists():\n",
    "        with open(label_path, \"r\") as f:\n",
    "            for line in f.read().strip().splitlines():\n",
    "                if line: boxes.append(yolo_to_xyxy(line, img_w, img_h))\n",
    "\n",
    "    x_starts = compute_tile_starts(img_w, TILE_SIZE, OVERLAP)\n",
    "    y_starts = compute_tile_starts(img_h, TILE_SIZE, OVERLAP)\n",
    "\n",
    "    for y0 in y_starts:\n",
    "        for x0 in x_starts:\n",
    "            # 1. Define Tile Geometry\n",
    "            x1_tile = x0 + TILE_SIZE\n",
    "            y1_tile = y0 + TILE_SIZE\n",
    "            \n",
    "            # 2. Crop (and Pad if necessary)\n",
    "            # We crop exactly what fits in the image\n",
    "            crop_w = min(x1_tile, img_w) - x0\n",
    "            crop_h = min(y1_tile, img_h) - y0\n",
    "            tile = img.crop((x0, y0, x0 + crop_w, y0 + crop_h))\n",
    "            \n",
    "            if PAD_TO_SQUARE and (crop_w < TILE_SIZE or crop_h < TILE_SIZE):\n",
    "                # Create a gray canvas 1280x1280\n",
    "                padded_tile = Image.new(\"RGB\", (TILE_SIZE, TILE_SIZE), (114, 114, 114))\n",
    "                # Paste the crop into top-left\n",
    "                padded_tile.paste(tile, (0, 0))\n",
    "                tile = padded_tile\n",
    "                # Note: valid area is 0..crop_w, 0..crop_h\n",
    "            \n",
    "            # 3. Process Boxes\n",
    "            tile_lines = []\n",
    "            for b in boxes:\n",
    "                if b is None: continue\n",
    "                cls, bx1, by1, bx2, by2 = b\n",
    "                \n",
    "                # Intersection logic\n",
    "                ix1 = max(bx1, x0)\n",
    "                iy1 = max(by1, y0)\n",
    "                ix2 = min(bx2, x0 + crop_w) # Clamp to actual image data, not pad\n",
    "                iy2 = min(by2, y0 + crop_h)\n",
    "\n",
    "                if ix2 <= ix1 or iy2 <= iy1: continue\n",
    "\n",
    "                # Shift to tile coordinates\n",
    "                tx1, ty1 = ix1 - x0, iy1 - y0\n",
    "                tx2, ty2 = ix2 - x0, iy2 - y0\n",
    "                \n",
    "                # Check area size to avoid slivers\n",
    "                bw, bh = tx2 - tx1, ty2 - ty1\n",
    "                if (bw * bh) / (TILE_SIZE * TILE_SIZE) < MIN_BOX_AREA_RATIO:\n",
    "                    continue\n",
    "\n",
    "                # IMPORTANT: Convert using the FULL TILE SIZE (1280), not just crop area\n",
    "                # This ensures coordinates are correct relative to the padded 1280x1280 image\n",
    "                tile_lines.append(xyxy_to_yolo(cls, tx1, ty1, tx2, ty2, TILE_SIZE, TILE_SIZE))\n",
    "\n",
    "            # 4. Save Logic (With Background Sampling)\n",
    "            has_birds = len(tile_lines) > 0\n",
    "            keep_tile = has_birds or (random.random() < KEEP_EMPTY_RATIO)\n",
    "\n",
    "            if keep_tile:\n",
    "                suffix = \"empty\" if not has_birds else f\"{len(tile_lines)}birds\"\n",
    "                out_base = f\"{base}_{x0}_{y0}_{suffix}\"\n",
    "                \n",
    "                tile.save(OUTPUT_IMAGES_DIR / f\"{out_base}.jpg\")\n",
    "                \n",
    "                # Even if empty, create empty txt file (YOLO standard)\n",
    "                with open(OUTPUT_LABELS_DIR / f\"{out_base}.txt\", \"w\") as f:\n",
    "                    if tile_lines:\n",
    "                        f.write(\"\\n\".join(tile_lines))\n",
    "                \n",
    "                total_tiles += 1\n",
    "                if has_birds: total_birds += len(tile_lines)\n",
    "\n",
    "print(f\"\\nüéâ DONE!\")\n",
    "print(f\"   -> Generated {total_tiles} tiles\")\n",
    "print(f\"   -> Containing {total_birds} annotated birds\")\n",
    "print(f\"   -> Saved to {OUTPUT_IMAGES_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5058c6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting Single-File Test on: DJI_20250203172651_0102_V.JPG\n",
      "üìÑ Found target image: CVAT/images/train/DJI_20250204070734_0054_V.JPG\n",
      "   -> Original Image Size: 4000x3000\n",
      "   -> Original Labels: 85\n",
      "   -> Generated 12 tiles for this image.\n",
      "üìÑ Found target image: CVAT/images/train/DJI_20250204070746_0060_V.JPG\n",
      "   -> Original Image Size: 4000x3000\n",
      "   -> Original Labels: 171\n",
      "   -> Generated 12 tiles for this image.\n",
      "üìÑ Found target image: CVAT/images/train/DJI_20250203172934_0179_V.JPG\n",
      "   -> Original Image Size: 4000x3000\n",
      "   -> Original Labels: 458\n",
      "   -> Generated 12 tiles for this image.\n",
      "üìÑ Found target image: CVAT/images/train/DJI_20250205165502_0449_V.JPG\n",
      "   -> Original Image Size: 4000x3000\n",
      "   -> Original Labels: 146\n",
      "   -> Generated 12 tiles for this image.\n",
      "üìÑ Found target image: CVAT/images/train/DJI_20250205170221_0657_V.JPG\n",
      "   -> Original Image Size: 4000x3000\n",
      "   -> Original Labels: 207\n",
      "   -> Generated 12 tiles for this image.\n",
      "üìÑ Found target image: CVAT/images/train/DJI_20250203174500_0618_V.JPG\n",
      "   -> Original Image Size: 4000x3000\n",
      "   -> Original Labels: 320\n",
      "   -> Generated 12 tiles for this image.\n",
      "üìÑ Found target image: CVAT/images/train/DJI_20250204071254_0206_V.JPG\n",
      "   -> Original Image Size: 4000x3000\n",
      "   -> Original Labels: 391\n",
      "   -> Generated 12 tiles for this image.\n",
      "üìÑ Found target image: CVAT/images/train/DJI_20250203174710_0680_V.JPG\n",
      "   -> Original Image Size: 4000x3000\n",
      "   -> Original Labels: 443\n",
      "   -> Generated 12 tiles for this image.\n",
      "üìÑ Found target image: CVAT/images/train/DJI_20250203172651_0102_V.JPG\n",
      "   -> Original Image Size: 4000x3000\n",
      "   -> Original Labels: 375\n",
      "   -> Generated 12 tiles for this image.\n",
      "üìÑ Found target image: CVAT/images/train/DJI_20250203173233_0264_V.JPG\n",
      "   -> Original Image Size: 4000x3000\n",
      "   -> Original Labels: 509\n",
      "   -> Generated 12 tiles for this image.\n",
      "\n",
      "üìä REPORT:\n",
      "Total Tiled Boxes: 5487\n",
      "Dropped (Too Small < 25px): 3\n",
      "Dropped (Low Visibility < 20%): 102\n",
      "\n",
      "‚úÖ Check folder: CVAT2check\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from math import ceil\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "# ==========================\n",
    "# CONFIGURATION\n",
    "# ==========================\n",
    "# Input paths\n",
    "INPUT_IMAGES_DIR = Path(\"CVAT/images/train\")\n",
    "INPUT_LABELS_DIR = Path(\"CVAT/labels/train\")\n",
    "\n",
    "# Output paths (Targeting your existing folder)\n",
    "OUTPUT_IMAGES_DIR = Path(\"TrainTiled/images\")\n",
    "OUTPUT_LABELS_DIR = Path(\"TrainTiled/labels\")\n",
    "\n",
    "# Ensure they exist (just in case)\n",
    "OUTPUT_IMAGES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUT_LABELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "# Tiling Settings\n",
    "TILE_SIZE = 1280          \n",
    "OVERLAP = 0.2             \n",
    "\n",
    "# Permissive Logic (Safe for small birds)\n",
    "MIN_BOX_PIXELS = 25       # Keep box if area > 25 pixels (5x5 pixels)\n",
    "MIN_VISIBILITY = 0.2      # Keep box if 20% of the bird is visible in this tile\n",
    "PAD_TO_SQUARE = True      # Pad edge tiles to 1280x1280\n",
    "\n",
    "# ==========================\n",
    "# HELPERS\n",
    "# ==========================\n",
    "\n",
    "def yolo_to_xyxy(line, img_w, img_h):\n",
    "    parts = line.strip().split()\n",
    "    if len(parts) != 5: return None\n",
    "    cls = int(parts[0])\n",
    "    cx, cy, bw, bh = map(float, parts[1:])\n",
    "    x1 = (cx - bw / 2) * img_w\n",
    "    y1 = (cy - bh / 2) * img_h\n",
    "    x2 = (cx + bw / 2) * img_w\n",
    "    y2 = (cy + bh / 2) * img_h\n",
    "    return cls, x1, y1, x2, y2\n",
    "\n",
    "def xyxy_to_yolo(cls, x1, y1, x2, y2, tile_w, tile_h):\n",
    "    bw = x2 - x1\n",
    "    bh = y2 - y1\n",
    "    cx = x1 + bw / 2\n",
    "    cy = y1 + bh / 2\n",
    "    \n",
    "    # Clamp to ensure proper YOLO normalization limits [0,1]\n",
    "    cx_n = max(0, min(1, cx / tile_w))\n",
    "    cy_n = max(0, min(1, cy / tile_h))\n",
    "    bw_n = max(0, min(1, bw / tile_w))\n",
    "    bh_n = max(0, min(1, bh / tile_h))\n",
    "    \n",
    "    return f\"{cls} {cx_n:.6f} {cy_n:.6f} {bw_n:.6f} {bh_n:.6f}\"\n",
    "\n",
    "def compute_tile_starts(img_dim, tile_size, overlap):\n",
    "    if img_dim <= tile_size: return [0]\n",
    "    stride = int(tile_size * (1 - overlap))\n",
    "    stride = max(1, stride)\n",
    "    num_tiles = ceil((img_dim - tile_size) / stride) + 1\n",
    "    starts = []\n",
    "    for i in range(num_tiles):\n",
    "        start = i * stride\n",
    "        if start + tile_size > img_dim:\n",
    "            start = img_dim - tile_size\n",
    "        if not starts or start != starts[-1]:\n",
    "            starts.append(start)\n",
    "    return starts\n",
    "\n",
    "# ==========================\n",
    "# MAIN EXECUTION\n",
    "# ==========================\n",
    "\n",
    "total_input_birds = 0\n",
    "total_output_birds = 0\n",
    "dropped_small = 0\n",
    "dropped_edge = 0\n",
    "\n",
    "print(f\"üöÄ Starting Single-File Test on: {TARGET_FILE}\")\n",
    "\n",
    "found_target = False\n",
    "\n",
    "for img_path in INPUT_IMAGES_DIR.iterdir():\n",
    "    # --- FILTER: ONLY RUN ON TARGET FILE ---\n",
    "    \n",
    "    found_target = True\n",
    "    print(f\"üìÑ Found target image: {img_path}\")\n",
    "\n",
    "    base = img_path.stem\n",
    "    label_path = INPUT_LABELS_DIR / f\"{base}.txt\"\n",
    "    \n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    img_w, img_h = img.size\n",
    "    \n",
    "    boxes = []\n",
    "    if label_path.exists():\n",
    "        with open(label_path, \"r\") as f:\n",
    "            for line in f.read().strip().splitlines():\n",
    "                if line: boxes.append(yolo_to_xyxy(line, img_w, img_h))\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Warning: No label file found at {label_path}\")\n",
    "    \n",
    "    print(f\"   -> Original Image Size: {img_w}x{img_h}\")\n",
    "    print(f\"   -> Original Labels: {len(boxes)}\")\n",
    "    total_input_birds += len(boxes)\n",
    "\n",
    "    x_starts = compute_tile_starts(img_w, TILE_SIZE, OVERLAP)\n",
    "    y_starts = compute_tile_starts(img_h, TILE_SIZE, OVERLAP)\n",
    "\n",
    "    tile_count = 0\n",
    "    for y0 in y_starts:\n",
    "        for x0 in x_starts:\n",
    "            # 1. Tile Geometry\n",
    "            x1_tile = x0 + TILE_SIZE\n",
    "            y1_tile = y0 + TILE_SIZE\n",
    "            \n",
    "            crop_w = min(x1_tile, img_w) - x0\n",
    "            crop_h = min(y1_tile, img_h) - y0\n",
    "            tile = img.crop((x0, y0, x0 + crop_w, y0 + crop_h))\n",
    "            \n",
    "            # Padding\n",
    "            if PAD_TO_SQUARE and (crop_w < TILE_SIZE or crop_h < TILE_SIZE):\n",
    "                padded_tile = Image.new(\"RGB\", (TILE_SIZE, TILE_SIZE), (114, 114, 114))\n",
    "                padded_tile.paste(tile, (0, 0))\n",
    "                tile = padded_tile\n",
    "\n",
    "            # 2. Process Boxes\n",
    "            tile_lines = []\n",
    "            \n",
    "            for b in boxes:\n",
    "                cls, bx1, by1, bx2, by2 = b\n",
    "                \n",
    "                orig_area = (bx2 - bx1) * (by2 - by1)\n",
    "                \n",
    "                ix1 = max(bx1, x0)\n",
    "                iy1 = max(by1, y0)\n",
    "                ix2 = min(bx2, x0 + crop_w) \n",
    "                iy2 = min(by2, y0 + crop_h)\n",
    "\n",
    "                if ix2 <= ix1 or iy2 <= iy1: \n",
    "                    continue\n",
    "\n",
    "                inter_w = ix2 - ix1\n",
    "                inter_h = iy2 - iy1\n",
    "                inter_area = inter_w * inter_h\n",
    "                \n",
    "                # Check 1: Pixels\n",
    "                if inter_area < MIN_BOX_PIXELS:\n",
    "                    dropped_small += 1\n",
    "                    continue \n",
    "\n",
    "                # Check 2: Visibility\n",
    "                visibility = inter_area / orig_area\n",
    "                if visibility < MIN_VISIBILITY:\n",
    "                    dropped_edge += 1\n",
    "                    continue\n",
    "\n",
    "                # Tile Coords\n",
    "                tx1 = ix1 - x0\n",
    "                ty1 = iy1 - y0\n",
    "                tx2 = ix2 - x0\n",
    "                ty2 = iy2 - y0\n",
    "                \n",
    "                tile_lines.append(xyxy_to_yolo(cls, tx1, ty1, tx2, ty2, TILE_SIZE, TILE_SIZE))\n",
    "\n",
    "            # Save ALL tiles for this test image (so we can verify birds AND backgrounds)\n",
    "            suffix = f\"{len(tile_lines)}birds\"\n",
    "            out_base = f\"{base}_{x0}_{y0}_{suffix}\"\n",
    "            \n",
    "            tile.save(OUTPUT_IMAGES_DIR / f\"{out_base}.jpg\")\n",
    "            with open(OUTPUT_LABELS_DIR / f\"{out_base}.txt\", \"w\") as f:\n",
    "                if tile_lines:\n",
    "                    f.write(\"\\n\".join(tile_lines))\n",
    "            \n",
    "            total_output_birds += len(tile_lines)\n",
    "            tile_count += 1\n",
    "\n",
    "    print(f\"   -> Generated {tile_count} tiles for this image.\")\n",
    "\n",
    "if not found_target:\n",
    "    print(f\"‚ùå ERROR: Could not find {TARGET_FILE} in {INPUT_IMAGES_DIR}\")\n",
    "else:\n",
    "    print(f\"\\nüìä REPORT:\")\n",
    "    print(f\"Total Tiled Boxes: {total_output_birds}\")\n",
    "    print(f\"Dropped (Too Small < 25px): {dropped_small}\")\n",
    "    print(f\"Dropped (Low Visibility < 20%): {dropped_edge}\")\n",
    "    print(f\"\\n‚úÖ Check folder: CVAT2check\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b7366d",
   "metadata": {},
   "source": [
    "## Zipped the tiled images and annotations and trained on googleColab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec0e232",
   "metadata": {},
   "outputs": [],
   "source": [
    "## RAN ON GOOGLE COLAB NOT HERE WITH T4 GPU\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "\n",
    "DATA_YAML = \"yolo_ready_dataset/data.yaml\"\n",
    "PROJECT_NAME = \"boeung_sne_drones\"\n",
    "RUN_NAME = \"pilot_run_v1\"\n",
    "\n",
    "\n",
    "if not os.path.exists(DATA_YAML):\n",
    "    raise FileNotFoundError(f\"Cannot find {DATA_YAML}. Did the pipeline finish successfully?\")\n",
    "\n",
    "\n",
    "print(\"Loading YOLOv8 Nano...\")\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "\n",
    "print(\" Starting Training...\")\n",
    "results = model.train(\n",
    "    data=DATA_YAML,\n",
    "\n",
    "\n",
    "    epochs=100,\n",
    "    imgsz=1280,\n",
    "    batch=5,\n",
    "    project=PROJECT_NAME,\n",
    "    name=RUN_NAME,\n",
    "    exist_ok=True,\n",
    "    cache=False\n",
    ")\n",
    "\n",
    "print(f\" Training Complete! Weights saved at: {PROJECT_NAME}/{RUN_NAME}/weights/best.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "birdc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
